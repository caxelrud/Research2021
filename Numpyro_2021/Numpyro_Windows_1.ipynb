{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UBER Numpyro on Windows\n",
    "#### Celso Axelrud\n",
    "#### Revision 1.0 - 4/24/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document describes the efforts to execute UBER Numpyro (https://github.com/pyro-ppl/numpyro) on Windows OS.\n",
    "\n",
    "Numpyro depends on JAX.\n",
    "JAX is available for Linux including on Google Collab environment but not officially for Windows.\n",
    "\n",
    "I have been collaborating by compiling and testing JAX for Windows.\n",
    "\n",
    "Currently, I am able to use Numpyro correctly for the CPU and GPU.\n",
    "\n",
    "Together with this notebook, several original project testing notebooks are available.\n",
    "\n",
    "Also, the notebooks for the book \"Statistical Rethinking- Richars McEreath\" are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPyro is a small probabilistic programming library that provides a NumPy backend for Pyro. We rely on JAX for automatic differentiation and JIT compilation to GPU / CPU.\n",
    "Pyro is a universal probabilistic programming language (PPL) written in Python. Pyro enables flexible and expressive deep probabilistic modeling, unifying the best of modern deep learning and Bayesian modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================\n",
    "# Numpyro Eight Schools example\n",
    "# https://github.com/pyro-ppl/numpyro\n",
    "\n",
    "import numpyro\n",
    "\n",
    "import numpyro.distributions as dist\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#numpyro.set_platform(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 8\n",
    "\n",
    "y = np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0])\n",
    "sigma = np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0])\n",
    "\n",
    "\n",
    "def eight_schools(J, sigma, y=None):\n",
    "\n",
    "     mu = numpyro.sample('mu', dist.Normal(0, 5))\n",
    "\n",
    "     tau = numpyro.sample('tau', dist.HalfCauchy(5))\n",
    "\n",
    "     with numpyro.plate('J', J):\n",
    "\n",
    "         theta = numpyro.sample('theta', dist.Normal(mu, tau))\n",
    "\n",
    "         numpyro.sample('obs', dist.Normal(theta, sigma), obs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|█| 1500/1500 [00:05<00:00, 254.76it/s, 15 steps of size 1.94e-01. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "        mu      4.09      3.19      4.01     -0.72      9.46    155.10      1.03\n",
      "       tau      4.66      3.70      3.87      0.76      8.84    114.24      1.02\n",
      "  theta[0]      6.46      6.23      5.73     -3.35     15.98    300.05      1.00\n",
      "  theta[1]      4.83      5.17      4.62     -3.23     14.04    307.49      1.00\n",
      "  theta[2]      3.74      5.87      3.78     -5.59     13.06    375.82      1.01\n",
      "  theta[3]      4.63      5.09      4.39     -1.97     14.31    392.76      1.00\n",
      "  theta[4]      3.15      4.56      3.26     -3.85     10.41    194.56      1.03\n",
      "  theta[5]      3.63      5.29      3.70     -3.84     12.01    483.57      1.00\n",
      "  theta[6]      6.65      5.67      6.06     -2.12     15.33    184.48      1.00\n",
      "  theta[7]      4.58      5.79      4.41     -3.72     13.76    452.71      1.00\n",
      "\n",
      "Number of divergences: 13\n"
     ]
    }
   ],
   "source": [
    "from jax import random\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "nuts_kernel = NUTS(eight_schools)\n",
    "mcmc = MCMC(nuts_kernel, num_warmup=500, num_samples=1000)\n",
    "rng_key = random.PRNGKey(0)\n",
    "mcmc.run(rng_key, J, sigma, y=y, extra_fields=('potential_energy',))\n",
    "\n",
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected log joint density: -56.14\n"
     ]
    }
   ],
   "source": [
    "pe = mcmc.get_extra_fields()['potential_energy']\n",
    "print('Expected log joint density: {:.2f}'.format(np.mean(-pe)))\n",
    "#Expected log joint density: -56.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|█| 1500/1500 [00:05<00:00, 253.22it/s, 7 steps of size 3.79e-01. a\n"
     ]
    }
   ],
   "source": [
    "from numpyro.infer.reparam import TransformReparam\n",
    "\n",
    "# Eight Schools example - Non-centered Reparametrization\n",
    "def eight_schools_noncentered(J, sigma, y=None):\n",
    "     mu = numpyro.sample('mu', dist.Normal(0, 5))\n",
    "     tau = numpyro.sample('tau', dist.HalfCauchy(5))\n",
    "     with numpyro.plate('J', J):\n",
    "         with numpyro.handlers.reparam(config={'theta': TransformReparam()}):\n",
    "             theta = numpyro.sample(\n",
    "                 'theta',\n",
    "                 dist.TransformedDistribution(dist.Normal(0., 1.),\n",
    "                                              dist.transforms.AffineTransform(mu, tau)))\n",
    "         numpyro.sample('obs', dist.Normal(theta, sigma), obs=y)\n",
    "\n",
    "nuts_kernel = NUTS(eight_schools_noncentered)\n",
    "mcmc = MCMC(nuts_kernel, num_warmup=500, num_samples=1000)\n",
    "rng_key = random.PRNGKey(0)\n",
    "mcmc.run(rng_key, J, sigma, y=y, extra_fields=('potential_energy',))\n",
    "#sample: 100%|██████████| 1500/1500 [00:06<00:00, 229.91it/s, 7 steps of size 3.79e-01. acc. prob=0.91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "           mu      4.07      3.49      3.95     -1.29     10.09    750.88      1.00\n",
      "          tau      3.88      3.31      2.93      0.03      8.24    551.26      1.00\n",
      "     theta[0]      6.18      5.36      5.69     -2.37     14.50    935.24      1.00\n",
      "     theta[1]      4.74      5.03      4.81     -4.20     12.21   1155.03      1.00\n",
      "     theta[2]      3.78      5.65      4.01     -5.87     11.28    959.08      1.00\n",
      "     theta[3]      4.51      4.92      4.31     -2.53     12.78   1104.54      1.00\n",
      "     theta[4]      3.40      4.74      3.55     -4.00     11.36   1025.76      1.00\n",
      "     theta[5]      3.61      4.76      3.76     -3.69     11.35    787.76      1.00\n",
      "     theta[6]      6.20      5.15      5.74     -1.59     14.26    911.82      1.00\n",
      "     theta[7]      5.03      5.36      4.69     -4.39     12.22   1129.99      1.00\n",
      "theta_base[0]      0.38      0.98      0.41     -1.30      1.83    775.55      1.00\n",
      "theta_base[1]      0.13      0.94      0.16     -1.50      1.47   1245.81      1.00\n",
      "theta_base[2]     -0.04      0.95     -0.03     -1.56      1.48    877.82      1.00\n",
      "theta_base[3]      0.10      0.93      0.11     -1.46      1.61   1044.21      1.00\n",
      "theta_base[4]     -0.10      0.94     -0.14     -1.73      1.32   1001.57      1.00\n",
      "theta_base[5]     -0.10      0.93     -0.11     -1.65      1.44    902.72      1.00\n",
      "theta_base[6]      0.38      0.97      0.38     -1.16      1.93    791.36      1.00\n",
      "theta_base[7]      0.12      1.01      0.16     -1.68      1.58   1075.65      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "mcmc.print_summary(exclude_deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected log joint density: -46.15\n"
     ]
    }
   ],
   "source": [
    "pe = mcmc.get_extra_fields()['potential_energy']\n",
    "# Compare with the earlier value\n",
    "print('Expected log joint density: {:.2f}'.format(np.mean(-pe)))  \n",
    "#Expected log joint density: -46.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LocScaleReparam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f1ff585bd091>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mnumpyro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreparam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'theta'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLocScaleReparam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpyro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'theta'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LocScaleReparam' is not defined"
     ]
    }
   ],
   "source": [
    "with numpyro.handlers.reparam(config={'theta': LocScaleReparam(centered=0)}):\n",
    "    theta = numpyro.sample('theta', dist.Normal(mu, tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.09555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.09555"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpyro.infer import Predictive\n",
    "\n",
    "# New School\n",
    "def new_school():\n",
    "     mu = numpyro.sample('mu', dist.Normal(0, 5))\n",
    "     tau = numpyro.sample('tau', dist.HalfCauchy(5))\n",
    "     return numpyro.sample('obs', dist.Normal(mu, tau))\n",
    "\n",
    "predictive = Predictive(new_school, mcmc.get_samples())\n",
    "samples_predictive = predictive(random.PRNGKey(1))\n",
    "print(np.mean(samples_predictive['obs']))  # doctest: +SKIP\n",
    "4.09555"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
